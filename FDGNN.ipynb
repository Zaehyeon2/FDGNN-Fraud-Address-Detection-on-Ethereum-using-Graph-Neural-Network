{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler, RandomSampler\n",
    "from torch.utils.data import random_split\n",
    "import dgl.data\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import dgl.data\n",
    "import pickle\n",
    "import glob\n",
    "import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "graphs = dgl.load_graphs('./fraud_homographs.dgl')\n",
    "\n",
    "for i, s in enumerate(graphs[0]):\n",
    "    graphs[0][i] = graphs[0][i].to('cuda:0')\n",
    "\n",
    "\n",
    "dataset = tuple(zip(graphs[0], graphs[1]['glabels'].argmax(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0007, 0.0007, 0.0063, 0.0011, 0.0015], device='cuda:0')\n",
      "tensor([0.0007, 0.0007, 0.0011,  ..., 0.0007, 0.0007, 0.0007], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "# Spliting Datset into training and testing\n",
    "train_dataset, val_dataset = random_split(dataset, (4459, 1115))\n",
    "\n",
    "\n",
    "# Obtaining weight of training datset and apply weightedrandomsampler\n",
    "labels = [l for _, l in train_dataset]\n",
    "\n",
    "target_list = torch.tensor([0, 1, 2, 3, 4])\n",
    "\n",
    "class_count = [0, 0, 0, 0, 0]\n",
    "\n",
    "for index, data in enumerate(train_dataset):\n",
    "    class_count[data[1]] += 1\n",
    "    \n",
    "\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float).to(device)\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "class_weights_all = class_weights[labels].to(device)\n",
    "\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=class_weights_all,\n",
    "    num_samples=len(class_weights_all),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "print(class_weights_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "import dgl.nn.pytorch as dglnn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import sys\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, n_classes, n_layer, pooling='mean', dropout=0.5, activation=F.relu):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcnlayer = torch.nn.ModuleList()\n",
    "\n",
    "        self.n_layer = n_layer\n",
    "        self.pooling = pooling\n",
    "\n",
    "        # Input Layer\n",
    "        self.gcnlayer.append(GraphConv(in_feats, h_feats, activation=activation))\n",
    "        # Hidden Layer\n",
    "        for layer in range(n_layer-1):\n",
    "            self.gcnlayer.append(GraphConv(h_feats, h_feats, activation=activation))\n",
    "        # Output Layer\n",
    "        self.gcnlayer.append(GraphConv(h_feats, n_classes))\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = in_feat\n",
    "        for i, layer in enumerate(self.gcnlayer):\n",
    "            h = layer(g, h)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        # Readout\n",
    "        hg = dgl.readout_nodes(g, 'h', op=self.pooling)\n",
    "        return hg\n",
    "\n",
    "def train(model, batch_size, n_epoch, optimizer):\n",
    "    train_dataloader = GraphDataLoader(\n",
    "    train_dataset, sampler=weighted_sampler, batch_size=batch_size, drop_last=False)\n",
    "    \n",
    "    gpu_mem = 0\n",
    "    for epoch in tqdm.tqdm(range(n_epoch)):\n",
    "        epoch_loss = 0\n",
    "        epoch_train_acc = 0\n",
    "        nb_data = 0\n",
    "        for iter, (batched_graph, labels) in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            pred = model(batched_graph, batched_graph.ndata['feature'].float())\n",
    "            loss = F.cross_entropy(pred, labels.to(device), weight=class_weights)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss\n",
    "            epoch_train_acc += accuracy_score(labels.cpu(), pred.cpu().argmax(1))\n",
    "            nb_data += len(labels)\n",
    "        epoch_loss /= (iter + 1)\n",
    "        epoch_train_acc /= nb_data\n",
    "\n",
    "        # print(epoch_loss, epoch_train_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model, average):\n",
    "    test_dataloader = GraphDataLoader(\n",
    "    val_dataset, drop_last=False)\n",
    "\n",
    "    y_pred = torch.tensor([], dtype=torch.int32).to('cuda:0')\n",
    "    y_label = torch.tensor([], dtype=torch.int32).to('cuda:0')\n",
    "\n",
    "    for batched_graph, labels in test_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata['feature'].float())\n",
    "        y_pred = torch.cat((y_pred, pred), 0)\n",
    "        y_label = torch.cat((y_label, labels.to(device)), 0)\n",
    "\n",
    "    print('Test accuracy:', accuracy_score(y_label.cpu(), y_pred.cpu().argmax(1)))\n",
    "\n",
    "    print('Precision: {}, Recall: {}, F1-score: {}'.format(precision_score(y_label.cpu(), y_pred.cpu().argmax(1), average=average), recall_score(y_label.cpu(), y_pred.cpu().argmax(1), average=average), f1_score(y_label.cpu(), y_pred.cpu().argmax(1), average=average)))\n",
    "    return y_label, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [02:14<06:42, 26.83s/it]"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "model = GCN(15, 32, 5, 4, activation=F.softmax).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "train(model, 2, 20, optimizer)\n",
    "\n",
    "y_label, y_pred = pred(model, 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Applting t-SNE to graph representation extrated by FDGNN\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = y_pred.cpu()\n",
    "\n",
    "n_components = 2\n",
    "\n",
    "model1 = TSNE(n_components=n_components)\n",
    "\n",
    "dot = model1.fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(X=dot[:,0], Y=dot[:,1], y_hat=y_label.cpu()))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = {0:'red', 1:'green', 2:'blue', 3:'skyblue', 4:'gray'}\n",
    "\n",
    "ax.scatter(df['X'], df['Y'], c=df['y_hat'].map(colors))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac840a94d6b6cfcab4979c4cbba837288ba41492109ceae8f331da715ad31117"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ICC2022': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
